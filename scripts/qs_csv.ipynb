{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T18:38:57.230486Z",
     "start_time": "2025-06-01T18:38:56.867897Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import requests, csv, time, os\n",
    "from typing import Optional, Dict\n",
    "from functools import lru_cache  # CACHE"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f178341221e27b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:36.959376Z",
     "start_time": "2025-05-18T15:38:36.956536Z"
    }
   },
   "source": [
    "# Basis-Endpunkt der MediaWiki API (Wikidata)\n",
    "API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "# HTTP-Header für API-Zugriffe, insbesondere ein benutzerdefinierter User-Agent (erforderlich laut API-Richtlinien)\n",
    "HEADERS = {\"User-Agent\": \"NFDI4Microbiota-QS-Generator/2.0 (info@example.com)\"}\n",
    "\n",
    "# Maximale Anzahl an Wiederholungsversuchen bei Fehlern (z. B. Rate-Limit, Timeout)\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Wartezeit in Sekunden zwischen Wiederholungsversuchen (Back-off-Zeit)\n",
    "BACKOFF_SECS = 3"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:36.971746Z",
     "start_time": "2025-05-18T15:38:36.968385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Führt eine GET-Anfrage an die Wikidata API aus, mit Fehlerbehandlung und automatischer Wiederholung.\n",
    "\"\"\"\n",
    "\n",
    "def _api_get(params: Dict) -> Dict:  # API\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            # Führe GET-Anfrage aus, mit Header und Timeout\n",
    "            r = requests.get(API_ENDPOINT, params=params, headers=HEADERS, timeout=25)\n",
    "\n",
    "            # Löst eine Ausnahme bei HTTP-Fehlern aus (z. B. 403, 500)\n",
    "            r.raise_for_status()\n",
    "\n",
    "            # JSON-Antwort dekodieren und zurückgeben\n",
    "            return r.json()\n",
    "\n",
    "        except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectionError):\n",
    "            # Bei Timeout oder Verbindungsfehler: warte (linear steigend) und versuche es erneut\n",
    "            wait = BACKOFF_SECS * attempt\n",
    "            print(f\"[warn] API timeout – Versuch {attempt}/{MAX_RETRIES}, warte {wait}s …\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            # Bei HTTP-Fehlern (z. B. 403, 500): abbrechen, nicht erneut versuchen\n",
    "            print(f\"[error] API HTTP {e.response.status_code}: {e.response.reason}\")\n",
    "            break\n",
    "    # Rückgabe bei Fehlschlag aller Versuche: leeres Dictionary\n",
    "    return {}"
   ],
   "id": "221a4f315677e669",
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "34c9006e2775dfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:36.983431Z",
     "start_time": "2025-05-18T15:38:36.981053Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Findet die Wikidata-QID zu einer gegebenen ORCID-ID mithilfe der Suchfunktion 'haswbstatement'.\n",
    "\"\"\"\n",
    "\n",
    "# Aktiviere Caching, um doppelte API-Anfragen zu vermeiden\n",
    "@lru_cache(maxsize=None)\n",
    "def find_qid_by_orcid(orcid: str) -> Optional[str]:\n",
    "    # Leere Eingabe sofort abbrechen\n",
    "    if not orcid:\n",
    "        return None\n",
    "    # Baue die spezielle Suchanfrage (CirrusSearch über ORCID property P496)\n",
    "    query = f'haswbstatement:P496=\"{orcid}\"'\n",
    "\n",
    "    # Anfrage an Wikidata-API stellen\n",
    "    data = _api_get(\n",
    "        {\n",
    "            \"action\": \"query\",\n",
    "            \"list\": \"search\",\n",
    "            \"srsearch\": query,\n",
    "            \"srlimit\": 1,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        # Extrahiere QID aus dem ersten Suchtreffer (z. B. \"Q12345\")\n",
    "        return data[\"query\"][\"search\"][0][\"title\"]\n",
    "    except (KeyError, IndexError):\n",
    "        # Kein Treffer gefunden oder Antwort unerwartet → gib None zurück\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "9e2a743109968da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:36.987760Z",
     "start_time": "2025-05-18T15:38:36.985651Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Sucht die Wikidata-QID für ein gegebenes Label (Name), optional sprachspezifisch.\n",
    "\"\"\"\n",
    "\n",
    "@lru_cache(maxsize=None)  # API/cache\n",
    "def find_qid_by_name(name: str, lang: str = \"en\") -> Optional[str]:\n",
    "    # Leere Eingabe direkt abbrechen\n",
    "    if not name:\n",
    "        return None\n",
    "\n",
    "    # Sende API-Anfrage an den wbsearchentities-Endpunkt (Wikidata-Suche)\n",
    "    data = _api_get(\n",
    "        {\n",
    "            \"action\": \"wbsearchentities\",\n",
    "            \"search\": name,\n",
    "            \"language\": lang,\n",
    "            \"type\": \"item\",\n",
    "            \"limit\": 1,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        # Gib die Q-ID des ersten Treffers zurück (z. B. \"Q123456\")\n",
    "        return data[\"search\"][0][\"id\"]\n",
    "    except (KeyError, IndexError):\n",
    "        # Kein Treffer oder unvollständige Antwort → gib None zurück\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:36.994692Z",
     "start_time": "2025-05-18T15:38:36.992128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Sucht nach einer Wikidata-QID für eine Institution anhand ihres Labels.\n",
    "Ergebnisse werden im lokalen Cache gespeichert.\n",
    "\"\"\"\n",
    "\n",
    "# Einfacher Cache für Institutionslabels → QID (oder None, falls nicht gefunden)\n",
    "inst_cache: Dict[str, Optional[str]] = {}\n",
    "\n",
    "def find_qid_by_institution_label(label: str) -> Optional[str]:  # API\n",
    "    # Falls keine Eingabe → abbrechen\n",
    "    if not label:\n",
    "        return None\n",
    "\n",
    "    # Falls Ergebnis schon im Cache → direkt zurückgeben\n",
    "    if label in inst_cache:\n",
    "        return inst_cache[label]\n",
    "\n",
    "    # Durchsuche Wikidata nach dem Label – zuerst auf Englisch, dann auf Deutsch\n",
    "    for lang in (\"en\", \"de\"):\n",
    "        data = _api_get({\n",
    "            \"action\": \"wbsearchentities\", \"search\": label, \"language\": lang,\n",
    "            \"type\": \"item\", \"limit\": 1, \"format\": \"json\"})\n",
    "\n",
    "        # Falls Treffer vorhanden → QID extrahieren und cachen\n",
    "        if data.get(\"search\"):\n",
    "            qid = data[\"search\"][0][\"id\"]\n",
    "            inst_cache[label] = qid\n",
    "\n",
    "            # Optionale Ausgabe, wenn deutsches Label verwendet wurde\n",
    "            if lang == \"de\":\n",
    "                print(f\"[info] Institution '{label}' über deutsches Label gefunden → {qid}\")\n",
    "            return qid\n",
    "\n",
    "    # Kein Treffer in beiden Sprachen → Cache mit None füllen\n",
    "    inst_cache[label] = None\n",
    "    return None"
   ],
   "id": "67cc8bbba6a9e068",
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "241bf54510cb35a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:37.002820Z",
     "start_time": "2025-05-18T15:38:36.998634Z"
    }
   },
   "source": [
    "def file_to_qs(infile: str, outfile: str) -> None:\n",
    "    # Bestimme Dateierweiterung (xls/xlsx oder csv)\n",
    "    ext = os.path.splitext(infile)[1].lower()\n",
    "\n",
    "    # Lese die Eingabedatei je nach Format ein\n",
    "    df = pd.read_excel(infile) if ext in {\".xlsx\", \".xls\"} else pd.read_csv(infile)\n",
    "\n",
    "    # Prüfe, ob alle erforderlichen Spalten vorhanden sind\n",
    "    required = {\"Name\", \"Institution\", \"ORCID\", \"ORCID-Link\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Fehlende Spalten: {', '.join(sorted(missing))}\")\n",
    "\n",
    "    # Initialisiere Ergebnisliste und Duplikat-Tracker\n",
    "    rows = []\n",
    "    processed = set()\n",
    "\n",
    "    # Iteriere über alle Zeilen der Eingabedatei\n",
    "    for _, r in df.iterrows():\n",
    "        name = str(r[\"Name\"]).strip()\n",
    "\n",
    "        # ORCID ggf. leer setzen, wenn NaN\n",
    "        orcid = str(r[\"ORCID\"]).strip() if pd.notna(r[\"ORCID\"]) else \"\"\n",
    "\n",
    "        # Dedupliziere anhand von Name + ORCID (kleingeschrieben)\n",
    "        key = (name.lower(), orcid)\n",
    "        if key in processed:\n",
    "            continue\n",
    "        processed.add(key)\n",
    "\n",
    "        # Institution und URL vorbereiten\n",
    "        inst_label = str(r[\"Institution\"]).strip()\n",
    "        url = r[\"ORCID-Link\"] if pd.notna(r[\"ORCID-Link\"]) else \"\"\n",
    "\n",
    "        # Prüfe, ob Person bereits existiert (über ORCID oder Name)\n",
    "        qid = find_qid_by_orcid(orcid) or find_qid_by_name(name)\n",
    "        if qid:\n",
    "            print(f\"[skip] {name} existiert bereits als {qid}\")\n",
    "            continue\n",
    "\n",
    "        # Versuche, die QID der Institution zu finden\n",
    "        inst_qid = find_qid_by_institution_label(inst_label)\n",
    "        if not inst_qid:\n",
    "            print(f\"[warn] Institution '{inst_label}' nicht gefunden ⇒ übersprungen\")\n",
    "            continue\n",
    "\n",
    "        # Baue QuickStatements-Zeile\n",
    "        rows.append({\n",
    "            \"qid\": \"\",\n",
    "            \"Len\": name,\n",
    "            \"P31\": \"Q5\",          # instance of → human\n",
    "            \"P496\": orcid,        # ORCID\n",
    "            \"S854\": url,          # Quelle (URL)\n",
    "            \"P108\": inst_qid,     # employer/affiliation\n",
    "        })\n",
    "\n",
    "        # Kurze Pause, um API nicht zu überlasten\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Falls keine neuen Zeilen → keine Ausgabe\n",
    "    if not rows:\n",
    "        print(\"Keine neuen Items – nichts exportiert.\")\n",
    "        return\n",
    "\n",
    "    # Schreibe die QuickStatements-Datei im CSV-Format\n",
    "    field_order = [\"qid\", \"Len\", \"P31\", \"P496\", \"S854\", \"P108\"]\n",
    "    with open(outfile, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=field_order)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    # Erfolgsmeldung mit Zeilenanzahl\n",
    "    print(f\"✓ {len(rows)} QuickStatements-Zeilen → {outfile}\")"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "caaab3d91226c44a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:39:14.192627Z",
     "start_time": "2025-05-18T15:38:37.008680Z"
    }
   },
   "source": [
    "# Pfad zur Eingabedatei mit Personen, Institutionen und ORCID-Informationen\n",
    "csv_input_path = \"import/input_with_orcid.csv\"\n",
    "\n",
    "# Pfad zur Zieldatei für generierte QuickStatements im CSV-Format\n",
    "csv_output_path = \"import/quickstatements.csv\"\n",
    "\n",
    "# Starte die Verarbeitung: prüfe vorhandene QIDs und erstelle neue QS-Zeilen\n",
    "file_to_qs(csv_input_path, csv_output_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] Alexander Sczyrba existiert bereits als Q30420936\n",
      "[skip] Jens Stoye existiert bereits als Q89498719\n",
      "[skip] Michael Beckstette existiert bereits als Q114411617\n",
      "[skip] Liren Huang existiert bereits als Q114780829\n",
      "[skip] Sebastian Jünemann existiert bereits als Q56948964\n",
      "[skip] Kassian Kobert existiert bereits als Q133094637\n",
      "[skip] Anandhi Iyappan existiert bereits als Q59196905\n",
      "[skip] Peer Bork existiert bereits als Q7160367\n",
      "[skip] Sarah Schulz existiert bereits als Q65162179\n",
      "[skip] Daniel Podlesny existiert bereits als Q133331882\n",
      "[skip] Manja Marz existiert bereits als Q87730329\n",
      "[skip] Winfried Göttsch existiert bereits als Q44200631\n",
      "[skip] Anderson Santos existiert bereits als Q39510481\n",
      "[skip] Ulisses Nunes da Rocha existiert bereits als Q47007256\n",
      "[skip] Martin Bole existiert bereits als Q102304978\n",
      "[skip] Adrian Fritz existiert bereits als Q133333363\n",
      "[skip] Alice McHardy existiert bereits als Q2646932\n",
      "[skip] Mattea Müller existiert bereits als Q56957915\n",
      "[skip] Fernando Meyer existiert bereits als Q84045251\n",
      "[skip] Gary Robertson existiert bereits als Q1482829\n",
      "[skip] Stephanie Aue existiert bereits als Q124637370\n",
      "[skip] Zhi-Luo Deng existiert bereits als Q133330529\n",
      "[skip] Alexander Goesmann existiert bereits als Q52422599\n",
      "[skip] Jochen Blom existiert bereits als Q88525311\n",
      "[skip] Stefan Janssen existiert bereits als Q57140228\n",
      "[skip] Frank Förster existiert bereits als Q42155371\n",
      "[skip] Karina Brinkrolf existiert bereits als Q114721947\n",
      "[skip] Anna Rehm existiert bereits als Q107174758\n",
      "[skip] Boyke Bunk existiert bereits als Q40442775\n",
      "[skip] Isabel Schober existiert bereits als Q90259120\n",
      "[skip] Jörg Overmann existiert bereits als Q76583148\n",
      "[skip] Lorenz Reimer existiert bereits als Q89708380\n",
      "[skip] Anke Becker existiert bereits als Q21253882\n",
      "[skip] Marcus Lechner existiert bereits als Q94461378\n",
      "[skip] Paul Klemm existiert bereits als Q89474635\n",
      "[skip] Katharina Grünwald existiert bereits als Q104686981\n",
      "[skip] Thomas Clavel existiert bereits als Q40442760\n",
      "[skip] Charlie Pauvert existiert bereits als Q103017355\n",
      "[skip] Catherine Gonzalez existiert bereits als Q57054455\n",
      "[skip] Thomas Hitch existiert bereits als Q3435482\n",
      "[skip] Barbara Götz existiert bereits als Q94745883\n",
      "[skip] Ziyad existiert bereits als Q84177389\n",
      "[skip] Justine Vandendorpe existiert bereits als Q62930742\n",
      "[skip] Konrad Förstner existiert bereits als Q18744528\n",
      "[skip] Muhammad Elhossary existiert bereits als Q30045548\n",
      "✓ 25 QuickStatements-Zeilen → import/quickstatements.csv\n"
     ]
    }
   ],
   "execution_count": 84
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
