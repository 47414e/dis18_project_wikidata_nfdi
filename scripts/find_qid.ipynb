{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:35:11.436689Z",
     "start_time": "2025-06-07T14:35:11.258689Z"
    }
   },
   "source": [
    "from typing import Optional, Dict\n",
    "from functools import lru_cache\n",
    "import requests, time\n",
    "\n",
    "# Base endpoint of the MediaWiki API (Wikidata)\n",
    "API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "# HTTP headers for API access, especially a custom User-Agent (required by API guidelines)\n",
    "HEADERS = {\"User-Agent\": \"NFDI4Microbiota-QS-Generator/2.0 (info@example.com)\"}\n",
    "\n",
    "# Maximum number of retry attempts on errors (e.g., rate limit, timeout)\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Waiting time in seconds between retries (back-off time)\n",
    "BACKOFF_SECS = 3\n",
    "\n",
    "\"\"\"\n",
    "Performs a GET request to the Wikidata API with error handling and automatic retries.\n",
    "\"\"\"\n",
    "\n",
    "def _api_get(params: Dict) -> Dict:  # API\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            # Execute GET request with headers and timeout\n",
    "            r = requests.get(API_ENDPOINT, params=params, headers=HEADERS, timeout=25)\n",
    "\n",
    "            # Raise exception on HTTP errors (e.g., 403, 500)\n",
    "            r.raise_for_status()\n",
    "\n",
    "            # Decode and return JSON response\n",
    "            return r.json()\n",
    "\n",
    "        except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectionError):\n",
    "            # On timeout or connection error: wait (linearly increasing) and retry\n",
    "            wait = BACKOFF_SECS * attempt\n",
    "            print(f\"[warn] API timeout – attempt {attempt}/{MAX_RETRIES}, waiting {wait}s …\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            # On HTTP errors (e.g., 403, 500): abort without retry\n",
    "            print(f\"[error] API HTTP {e.response.status_code}: {e.response.reason}\")\n",
    "            break\n",
    "    # Return an empty dictionary if all attempts fail\n",
    "    return {}\n",
    "\n",
    "\"\"\"\n",
    "Finds the Wikidata QID for a given ORCID iD using the 'haswbstatement' search function.\n",
    "\"\"\"\n",
    "\n",
    "# Enable caching to avoid duplicate API requests\n",
    "@lru_cache(maxsize=None)\n",
    "def find_qid_by_orcid(orcid: str) -> Optional[str]:\n",
    "    # Immediately abort on empty input\n",
    "    if not orcid:\n",
    "        return None\n",
    "    # Build the specific search query (CirrusSearch using ORCID property P496)\n",
    "    query = f'haswbstatement:P496=\"{orcid}\"'\n",
    "\n",
    "    # Submit request to Wikidata API\n",
    "    data = _api_get(\n",
    "        {\n",
    "            \"action\": \"query\",\n",
    "            \"list\": \"search\",\n",
    "            \"srsearch\": query,\n",
    "            \"srlimit\": 1,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        # Extract QID from the first search result (e.g., \"Q12345\")\n",
    "        return data[\"query\"][\"search\"][0][\"title\"]\n",
    "    except (KeyError, IndexError):\n",
    "        # No result found or unexpected response → return None\n",
    "        return None\n"
   ],
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
